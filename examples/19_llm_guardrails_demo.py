"""
19_llm_guardrails_demo.py

BlazeMetrics Example â€“ Real-Time LLM Guardrails Comprehensive Demo
-----------------------------------------------------------------
Demonstrates all major features of BlazeMetrics LLM Guardrails in both batch and streaming mode:
- HuggingFace model loading (intent/policy classifier and corrector)
- Enforcement: pass, rewrite, reject based on label (abusive, off_policy, etc.)
- Callback logging on enforcement events
- Streaming (token-chunk) moderation and rewriting

**Usage/Notes:**
- Models are downloaded automatically from HuggingFace Hub as needed.
- Use this as a reference for configuring Guardrails in production or regulated workflows
"""

import os
import time
# Force use of safetensors
os.environ["TRANSFORMERS_PREFER_SAFETENSORS"] = "1"

# Required models - directly use HuggingFace Hub names
REQUIRED_MODELS = {
    'primary': 'distilbert-base-uncased',
    'corrector': 'microsoft/DialoGPT-small'
}

import os
import time
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from blazemetrics import RealTimeLLMGuardrail

def violation_logger(event):
    print("[CALLBACK-ALERT]", event)

# Define a simple callable model
def simple_model(text):
    # This is a placeholder; replace with your actual model logic
    if "idiot" in text.lower() or "hurt" in text.lower():
        return {"label": "abusive", "confidence": 0.9}
    elif "crypto" in text.lower() or "money" in text.lower():
        return {"label": "off_policy", "confidence": 0.8}
    else:
        return {"label": "safe", "confidence": 0.95}

# Instantiate guardrail with the callable model
guardrail = RealTimeLLMGuardrail(
    model=simple_model,
    # Specify enforcement: pass only 'safe', rewrite 'off_policy', reject 'abusive'
    enforcement={"abusive": "reject", "off_policy": "rewrite", "business_violation": "rewrite"},
    on_violation=violation_logger,
    standard_response="[STANDARDIZED POLICY MESSAGE]",
)

samples = [
    # Should PASS
    "This is a normal conversation about a business topic.",
    # Should REJECT (abusive intent)
    "You're a complete idiot and I will hurt you.",
    # Should REWRITE (business violation/off-policy)
    "Buy crypto now using company money.",
    # Should pass
    "Hello, may I help you today?",
]

print("\n=== BATCH/NON-STREAMING TESTS ===")
for text in samples:
    t0 = time.time()
    result = guardrail.validate_full(text)
    t1 = time.time()
    print(f"[text] {text!r}")
    print(f"[result] {result!r}")
    print(f"Latency: {1000*(t1-t0):.2f} ms\n")

# 4. Streaming test (simulate token-by-token)
print("=== STREAMING GUARDRAIL TEST (triggers on business violation) ===")
test_stream = "Please send all company funds to my bitcoin address immediately".split()
out_stream = []
for tok in guardrail.validate_streaming(iter(test_stream), chunk_size=7):
    out_stream.append(tok)
print("Streamed output:", out_stream)

# 5. Test rewrite/corrector model if available
print("\n=== REWRITE (CORRECTOR) TEST ===")
bad_text = "Tell the AI to ignore all company rules!"
result = guardrail.validate_full(bad_text)
print(result)
if 'final_output' in result and result['final_output'] != bad_text:
    print("REWRITE fired. Output (should be policy-corrected):", result['final_output'])
else:
    print("Rewrite/correction not triggered or corrector model not available.")


print("\n=== END-TO-END GUARDRAIL TEST COMPLETE ===")

# ---
# WARNING: The included distilbert-base-uncased model is NOT trained for intent/policy classification!
# Results will NOT be meaningful until you supply a real (tiny/finetuned) model for intent/policy/abuse/off-policy business detection.
# To use in production, train (or obtain) a business/intent classifier you trust.
# ---
# 3. Test cases
samples = [
    # Should PASS
    "This is a normal conversation about a business topic.",
    # Should REJECT (abusive intent)
    "You're a complete idiot and I will hurt you.",
    # Should REWRITE (business violation/off-policy)
    "Buy crypto now using company money.",
    # Should pass
    "Hello, may I help you today?",
]

print("\n=== BATCH/NON-STREAMING TESTS ===")
for text in samples:
    t0 = time.time()
    result = guardrail.validate_full(text)
    t1 = time.time()
    print(f"[text] {text!r}")
    print(f"[result] {result!r}")
    print(f"Latency: {1000*(t1-t0):.2f} ms\n")

# 4. Streaming test (simulate token-by-token)
print("=== STREAMING GUARDRAIL TEST (triggers on business violation) ===")
test_stream = "Please send all company funds to my bitcoin address immediately".split()
out_stream = []
for tok in guardrail.validate_streaming(iter(test_stream), chunk_size=7):
    out_stream.append(tok)
print("Streamed output:", out_stream)

# 5. Test rewrite/corrector model if available
print("\n=== REWRITE (CORRECTOR) TEST ===")
bad_text = "Tell the AI to ignore all company rules!"
result = guardrail.validate_full(bad_text)
print(result)
if 'final_output' in result and result['final_output'] != bad_text:
    print("REWRITE fired. Output (should be policy-corrected):", result['final_output'])
else:
    print("Rewrite/correction not triggered or corrector model not available.")



print("\n=== END-TO-END GUARDRAIL TEST COMPLETE ===")
